import streamlit as st
import cv2
import tempfile
import numpy as np
from ultralytics import YOLO
import time

# Load YOLOv8 segmentation model
model_path = "best_potholes_1_class.pt"  # Update with your trained model path
model = YOLO(model_path)

# Streamlit UI
st.title("YOLOv8 Segmentation - Image & Video")

# Sidebar for options
task = st.sidebar.selectbox("Select Task", ["Image Segmentation", "Video Segmentation"])

if task == "Image Segmentation":
    st.header("Upload an Image")
    uploaded_image = st.file_uploader("Choose an image...", type=["jpg", "png", "jpeg"])

    if uploaded_image is not None:
        # Convert file to OpenCV format
        file_bytes = np.asarray(bytearray(uploaded_image.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)

        # Run segmentation
        results = model(image)

        for result in results:
            segmented_image = result.plot()  # YOLOv8 visualization

        st.image(segmented_image, caption="Segmented Output", channels="BGR", use_column_width=True)

        # Save output image
        output_image_path = "segmented_image.jpg"
        cv2.imwrite(output_image_path, segmented_image)

        # Download segmented image
        with open(output_image_path, "rb") as f:
            st.download_button("Download Segmented Image", f, file_name="segmented_image.jpg")

elif task == "Video Segmentation":
    st.header("Upload a Video")
    uploaded_video = st.file_uploader("Choose a video...", type=["mp4", "avi", "mov"])

    if uploaded_video is not None:
        # Save uploaded file to a temporary location
        temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
        temp_video.write(uploaded_video.read())

        st.video(temp_video.name)  # Display uploaded video

        if st.button("Process Video"):
            cap = cv2.VideoCapture(temp_video.name)
            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = cap.get(cv2.CAP_PROP_FPS)  # Get input video FPS
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frames

            # Ensure duration remains the same
            duration = frame_count / fps

            out_video_path = "output_segmented.mp4"
            out = cv2.VideoWriter(out_video_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (frame_width, frame_height))

            stframe = st.empty()  # Placeholder for displaying frames

            frame_time = 1 / fps  # Time per frame
            start_time = time.time()  # Track processing start time
            processed_frames = 0  # Track the number of processed frames

            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break

                # Run segmentation on each frame
                results = model(frame)
                for result in results:
                    segmented_frame = result.plot()  # YOLOv8 visualization

                out.write(segmented_frame)  # Save frame to output video
                stframe.image(segmented_frame, channels="BGR", use_column_width=True)  # Display segmented frame
                processed_frames += 1  # Increment processed frame count

                # Ensure correct playback speed
                expected_time = processed_frames * frame_time
                elapsed_time = time.time() - start_time

                if elapsed_time < expected_time:
                    time.sleep(expected_time - elapsed_time)  # Adjust processing time to match input speed

            cap.release()
            out.release()

            st.success("Processing Complete! Download Segmented Video Below")
            with open(out_video_path, "rb") as f:
                st.download_button("Download Segmented Video", f, file_name="segmented_output.mp4")